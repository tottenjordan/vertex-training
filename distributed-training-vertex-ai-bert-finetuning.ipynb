{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09598e8-8582-4fe8-8e4f-98593c4e6103",
   "metadata": {},
   "source": [
    "# BERT fine-tuning with Vertex AI\n",
    "\n",
    "Building example from [this notebook example](https://github.com/RajeshThallam/vertex-ai-labs/blob/main/03-distributed-training-text/03-distributed-training-vertex-ai-bert-finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d6bd40-e201-410b-bcb4-87b93b2d47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user --upgrade google-cloud-aiplatform -q\n",
    "# !pip install --user --upgrade kfp -q\n",
    "# !pip install --user --upgrade google-cloud-pipeline-components -q\n",
    "# !pip install --user --upgrade google-cloud-bigquery-datatransfer -q\n",
    "# !pip install --user tf-models-official==2.11.0 tensorflow-text==2.11.0 -q\n",
    "# pip install tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc1ceec-8048-42aa-89df-e00b75c77bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d449ca34-fec8-402b-8bd8-ce2af363fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d2c73ae-7a65-4758-9808-be97b1eb7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import google.auth\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "from google.cloud.aiplatform_v1beta1 import types\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import exceptions\n",
    "\n",
    "from google.cloud.aiplatform.utils import JobClientWithOverride\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow_io import bigquery as tfio_bq\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2090091d-e5e7-42b3-8c73-b9b17a00efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'jtv7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a98332-aa40-4934-92a2-5cf7e494eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT = hybrid-vertex\n",
      "STAGING_BUCKET = gs://jtv7-hybrid-vertex-bucket\n",
      "VERTEX_SA = 934903580331-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "creds, PROJECT = google.auth.default()\n",
    "REGION = 'us-central1'\n",
    "\n",
    "STAGING_BUCKET = f'gs://{PREFIX}-{PROJECT}-bucket'\n",
    "BUCKET_NAME = STAGING_BUCKET\n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'\n",
    "\n",
    "print(f\"PROJECT = {PROJECT}\")\n",
    "print(f\"STAGING_BUCKET = {STAGING_BUCKET}\")\n",
    "print(f\"VERTEX_SA = {VERTEX_SA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07031db4-32d6-4088-a879-a590e884e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://jtv7-hybrid-vertex-bucket/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION $STAGING_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a471453e-f45c-4eac-8cbd-e7e1257b23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORBOARD_NAME = f\"tb-bert-tune-{PREFIX}\"  # @param {type:\"string\"}\n",
    "\n",
    "# if (\n",
    "#     TENSORBOARD_NAME == \"\"\n",
    "#     or TENSORBOARD_NAME is None\n",
    "#     or TENSORBOARD_NAME == \"[your-tensorboard-name]\"\n",
    "# ):\n",
    "#     TENSORBOARD_NAME = PROJECT + \"-tb-\" #+ UUID\n",
    "\n",
    "# tensorboard = vertex_ai.Tensorboard.create(\n",
    "#     display_name=TENSORBOARD_NAME, project=PROJECT, location=REGION\n",
    "# )\n",
    "# TENSORBOARD = tensorboard.gca_resource.name\n",
    "# print(\"TENSORBOARD:\", TENSORBOARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e088c-2694-4daa-ac1e-7d3339f991a9",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc2ba8a-80b1-45f6-8a68-bd6639a22ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_path: /home/jupyter/distributed-training/datasets/aclImdb_v1.tar.gz\n",
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 3s 0us/step\n",
      "dataset_dir: /home/jupyter/distributed-training/datasets/aclImdb\n",
      "train_dir: /home/jupyter/distributed-training/datasets/aclImdb/train\n"
     ]
    }
   ],
   "source": [
    "local_dir = os.path.expanduser('~')\n",
    "local_dir = f'{local_dir}/distributed-training/datasets'\n",
    "\n",
    "if tf.io.gfile.exists(local_dir):\n",
    "    tf.io.gfile.rmtree(local_dir)\n",
    "tf.io.gfile.makedirs(local_dir)\n",
    "\n",
    "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "local_path = f'{local_dir}/aclImdb_v1.tar.gz'\n",
    "print(f'local_path: {local_path}')\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    local_path\n",
    "    , url\n",
    "    , untar=True\n",
    "    , cache_dir=local_dir\n",
    "    , cache_subdir='.'\n",
    ")\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "print(f'dataset_dir: {dataset_dir}')\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "print(f'train_dir: {train_dir}')\n",
    "\n",
    "# remove unused folders to make it easier to load the data\n",
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "856b2f4d-f724-4950-849a-94355c764945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(train_dir, test_dir, val_split, seed):\n",
    "    \n",
    "    train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        train_dir,\n",
    "        validation_split=val_split,\n",
    "        subset='training',\n",
    "        seed=seed)\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "    \n",
    "    train_ds = train_ds.unbatch()\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        train_dir,\n",
    "        validation_split=val_split,\n",
    "        subset='validation',\n",
    "        seed=seed).unbatch()\n",
    "\n",
    "    test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        test_dir).unbatch()\n",
    "\n",
    "    return train_ds, val_ds, test_ds, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85e9bf9-b20e-40b0-ba8d-c681270de80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "val_split = 0.2\n",
    "test_dir = f'{dataset_dir}/test'\n",
    "\n",
    "train_ds, val_ds, test_ds, class_names = (\n",
    "    create_splits(train_dir, test_dir, val_split, seed)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9bbd940-a361-4801-8377-f25ea6c4cf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
      "Label : 0 (neg)\n",
      "Review: b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
      "Label : 0 (neg)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(2):\n",
    "    print(f'Review: {text.numpy()}')\n",
    "    label = label.numpy()\n",
    "    print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa44626d-73a5-44a2-b569-804dfbbb0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(text_fragment, label):\n",
    "    \"\"\"Serializes text fragment and label in tf.Example.\"\"\"\n",
    "    \n",
    "    def _bytes_feature(value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    feature = {\n",
    "        'text_fragment': _bytes_feature(text_fragment),\n",
    "        'label': _int64_feature(label)\n",
    "    }\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "    \n",
    "def tf_serialize_example(text_fragment, label):\n",
    "  tf_string = tf.py_function(\n",
    "    serialize_example,\n",
    "    (text_fragment, label), \n",
    "    tf.string)      \n",
    "  return tf.reshape(tf_string, ()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5e9e7da-3973-4ae9-a6b9-7d8eb219765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecords_folder = '{}/tfrecords'.format(os.path.expanduser('~'))\n",
    "if tf.io.gfile.exists(tfrecords_folder):\n",
    "    tf.io.gfile.rmtree(tfrecords_folder)\n",
    "tf.io.gfile.makedirs(tfrecords_folder)\n",
    "\n",
    "filenames = ['train.tfrecords', 'valid.tfrecords', 'test.tfrecords']\n",
    "for file_name, dataset in zip(filenames, [train_ds, val_ds, test_ds]):\n",
    "    writer = tf.data.experimental.TFRecordWriter(os.path.join(tfrecords_folder, file_name))\n",
    "    writer.write(dataset.map(tf_serialize_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7e1c31e-25ea-422c-a8f4-842adef23a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"\\n\\xd1\\x07\\n\\xbe\\x07\\n\\rtext_fragment\\x12\\xac\\x07\\n\\xa9\\x07\\n\\xa6\\x07Need I say more? The reason the GOOD Australian version of Kath and Kim was, as mentioned, good, was because of it's hilariously funny originality. The reason this new American-ised version is so terrible is because a lot of it is taken straight from the original. Not to mention the unfaithfulness to the characters. Kath is meant to be a dag. Kim is meant to be fat. Kel (or Phil as they have dubbed him) is meant to be pathetic. Brett (or Craig) is meant to be a loser, not a person who acts like he's on heroin and finishes every sentence with 'dude'. Thank God Szubanski didn't sell her rights to Sharon, she'd probably end up being a tall thin blonde who Kim likes.<br /><br />Kath and Kim are MOTHER AND DAUGHTER. They are not meant to look 2 years apart. And they are not meant to giggle like school girls. This show is a disgrace to even share the same title as the Australian version. America: get your own television shows.\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00\", shape=(), dtype=string)\n",
      "tf.Tensor(b'\\n\\xb0\\t\\n\\x9d\\t\\n\\rtext_fragment\\x12\\x8b\\t\\n\\x88\\t\\n\\x85\\tI\\'ve often heard people express disappointment that Mazursky\\'s \"Tempest\" has little to do with Shakespeare\\'s original. In my opinion, that is both true and false, but most of all, it\\'s a bad starting point for offering critique. A work of art should never be criticised for what it isn\\'t, but for what it is. The movie \"Tempest\" is nothing like a faithful rendition of the play, but to my mind, it is faithful to Shakespeare\\'s work in spirit. What \"Tempest\" is, then, is perhaps one of the most successful experimental films of all time. No, not experimental as in hand- held camera and mumbled dialogue, but experimental as in exploring the convolutions of a story without undue regard for box office earnings. Mazursky\\'s Tempest is epic, sad, realistic, joyous, full of life, but most of all, it is imaginative. Cassavetes portrayal of Philip/Prospero is in itself worth a 10/10 rating, and when you add Gena Rowlands, Susan Sarandon, a wonderfully deep Molly Ringwald, Raul Julia, the dialogue, the music and the exquisitely suggestive little tableaux scattered throughout the picture... I rest my case. One of the best movies of the 80\\'s. Don\\'t miss it.\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x01', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for record in tf.data.TFRecordDataset([os.path.join(tfrecords_folder, file_name)]).take(2):\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba8783ca-06ce-46b9-a12c-87e8cad11748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/jupyter/tfrecords/train.tfrecords [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 26.5 MiB/ 26.5 MiB]                                                \n",
      "Operation completed over 1 objects/26.5 MiB.                                     \n",
      "Copying file:///home/jupyter/tfrecords/valid.tfrecords [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  6.6 MiB/  6.6 MiB]                                                \n",
      "Operation completed over 1 objects/6.6 MiB.                                      \n",
      "Copying file:///home/jupyter/tfrecords/test.tfrecords [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 32.3 MiB/ 32.3 MiB]                                                \n",
      "Operation completed over 1 objects/32.3 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "gcs_paths = [f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/train',\n",
    "             f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/valid',\n",
    "             f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/test']\n",
    "\n",
    "for filename, gcs_path in zip(filenames, gcs_paths):\n",
    "    local_file_path = os.path.join(tfrecords_folder, filename)\n",
    "    gcs_file_path = f'{gcs_path}/{filename}'\n",
    "    !gsutil cp {local_file_path} {gcs_file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "008c8aa2-e0c6-4fcd-8a77-7c9afc9bc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-4'\n",
    "TRAIN_BASE_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-11:latest'\n",
    "# TRAIN_BASE_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-11:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d51adb5-df0a-49ca-913b-4b95a70930a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf scripts/trainer\n",
    "! mkdir -p scripts/trainer\n",
    "! touch scripts/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea7c3847-9f27-4e33-8919-058c2054181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scripts/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/trainer/task.py\n",
    "\n",
    "\n",
    "# Copyright 2021 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "import time\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "from official.nlp import optimization \n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "\n",
    "TFHUB_HANDLE_ENCODER = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
    "TFHUB_HANDLE_PREPROCESS = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "LOCAL_TB_FOLDER = '/tmp/logs'\n",
    "LOCAL_SAVED_MODEL_DIR = '/tmp/saved_model'\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('steps_per_epoch', 625, 'Steps per training epoch')\n",
    "flags.DEFINE_integer('eval_steps', 150, 'Evaluation steps')\n",
    "flags.DEFINE_integer('epochs', 2, 'Nubmer of epochs')\n",
    "flags.DEFINE_integer('per_replica_batch_size', 32, 'Per replica batch size')\n",
    "flags.DEFINE_integer('TRAIN_NGPU', 1, '')\n",
    "flags.DEFINE_integer('replica_count', 1, '')\n",
    "flags.DEFINE_integer('reduction_cnt', 0, '')\n",
    "\n",
    "flags.DEFINE_string('training_data_path', f'/bert-finetuning/imdb/tfrecords/train', 'Training data GCS path')\n",
    "flags.DEFINE_string('validation_data_path', f'/bert-finetuning/imdb/tfrecords/valid', 'Validation data GCS path')\n",
    "flags.DEFINE_string('testing_data_path', f'/bert-finetuning/imdb/tfrecords/test', 'Testing data GCS path')\n",
    "\n",
    "flags.DEFINE_string('job_dir', f'/jobs', 'A base GCS path for jobs')\n",
    "flags.DEFINE_string('job_id', 'default', 'unique_id for experiment runs')\n",
    "flags.DEFINE_string('TRAIN_GPU', 'NA', '')\n",
    "flags.DEFINE_string('experiment_run', 'NA', '')\n",
    "flags.DEFINE_string('experiment_name', 'NA', '')\n",
    "\n",
    "\n",
    "flags.DEFINE_enum('strategy', 'multiworker', ['single', 'mirrored', 'multiworker'], 'Distribution strategy')\n",
    "flags.DEFINE_enum('auto_shard_policy', 'auto', ['auto', 'data', 'file', 'off'], 'Dataset sharing strategy')\n",
    "\n",
    "auto_shard_policy = {\n",
    "    'auto': tf.data.experimental.AutoShardPolicy.AUTO,\n",
    "    'data': tf.data.experimental.AutoShardPolicy.DATA,\n",
    "    'file': tf.data.experimental.AutoShardPolicy.FILE,\n",
    "    'off': tf.data.experimental.AutoShardPolicy.OFF,\n",
    "}\n",
    "\n",
    "\n",
    "def create_unbatched_dataset(tfrecords_folder):\n",
    "    \"\"\"Creates an unbatched dataset in the format required by the \n",
    "       sentiment analysis model from the folder with TFrecords files.\"\"\"\n",
    "    \n",
    "    feature_description = {\n",
    "        'text_fragment': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    }\n",
    "\n",
    "    def _parse_function(example_proto):\n",
    "        parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        return parsed_example['text_fragment'], parsed_example['label']\n",
    "  \n",
    "    file_paths = [f'{tfrecords_folder}/{file_path}' for file_path in tf.io.gfile.listdir(tfrecords_folder)]\n",
    "    dataset = tf.data.TFRecordDataset(file_paths)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def configure_dataset(ds, auto_shard_policy):\n",
    "    \"\"\"\n",
    "    Optimizes the performance of a dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = (\n",
    "        auto_shard_policy\n",
    "    )\n",
    "    \n",
    "    ds = ds.repeat(-1).cache()\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    ds = ds.with_options(options)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def create_input_pipelines(train_dir, valid_dir, test_dir, batch_size, auto_shard_policy):\n",
    "    \"\"\"Creates input pipelines from Imdb dataset.\"\"\"\n",
    "    \n",
    "    train_ds = create_unbatched_dataset(train_dir)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    train_ds = configure_dataset(train_ds, auto_shard_policy)\n",
    "    \n",
    "    valid_ds = create_unbatched_dataset(valid_dir)\n",
    "    valid_ds = valid_ds.batch(batch_size)\n",
    "    valid_ds = configure_dataset(valid_ds, auto_shard_policy)\n",
    "    \n",
    "    test_ds = create_unbatched_dataset(test_dir)\n",
    "    test_ds = test_ds.batch(batch_size)\n",
    "    test_ds = configure_dataset(test_ds, auto_shard_policy)\n",
    "\n",
    "    return train_ds, valid_ds, test_ds\n",
    "\n",
    "\n",
    "def build_classifier_model(tfhub_handle_preprocess, tfhub_handle_encoder):\n",
    "    \"\"\"Builds a simple binary classification model with BERT trunk.\"\"\"\n",
    "    \n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    \n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n",
    "def copy_tensorboard_logs(local_path: str, gcs_path: str):\n",
    "    \"\"\"Copies Tensorboard logs from a local dir to a GCS location.\n",
    "    \n",
    "    After training, batch copy Tensorboard logs locally to a GCS location. This can result\n",
    "    in faster pipeline runtimes over streaming logs per batch to GCS that can get bottlenecked\n",
    "    when streaming large volumes.\n",
    "    \n",
    "    Args:\n",
    "      local_path: local filesystem directory uri.\n",
    "      gcs_path: cloud filesystem directory uri.\n",
    "    Returns:\n",
    "      None.\n",
    "    \"\"\"\n",
    "    pattern = '{}/*/events.out.tfevents.*'.format(local_path)\n",
    "    local_files = tf.io.gfile.glob(pattern)\n",
    "    gcs_log_files = [local_file.replace(local_path, gcs_path) for local_file in local_files]\n",
    "    for local_file, gcs_file in zip(local_files, gcs_log_files):\n",
    "        tf.io.gfile.copy(local_file, gcs_file)\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    del argv\n",
    "    \n",
    "    def _is_chief(task_type, task_id):\n",
    "        return ((task_type == 'chief' or task_type == 'worker') and task_id == 0) or task_type is None\n",
    "        \n",
    "    \n",
    "    logging.info('Setting up training.')\n",
    "    logging.info('   epochs: {}'.format(FLAGS.epochs))\n",
    "    logging.info('   steps_per_epoch: {}'.format(FLAGS.steps_per_epoch))\n",
    "    logging.info('   eval_steps: {}'.format(FLAGS.eval_steps))\n",
    "    logging.info('   strategy: {}'.format(FLAGS.strategy))\n",
    "    logging.info('   job_id: {}'.format(FLAGS.job_id))\n",
    "    logging.info('   TRAIN_GPU: {}'.format(FLAGS.TRAIN_GPU))\n",
    "    logging.info('   TRAIN_NGPU: {}'.format(FLAGS.TRAIN_NGPU))\n",
    "    logging.info('   replica_count: {}'.format(FLAGS.replica_count))\n",
    "    logging.info('   reduction_cnt: {}'.format(FLAGS.reduction_cnt))\n",
    "    logging.info('   experiment_name: {}'.format(FLAGS.experiment_name))\n",
    "    logging.info('   experiment_run: {}'.format(FLAGS.experiment_run))\n",
    "    \n",
    "    tb_dir = os.getenv('AIP_TENSORBOARD_LOG_DIR', LOCAL_TB_FOLDER)\n",
    "    model_dir = os.getenv('AIP_MODEL_DIR', LOCAL_SAVED_MODEL_DIR)\n",
    "    logging.info(f'AIP_TENSORBOARD_LOG_DIR = {tb_dir}')\n",
    "    logging.info(f'AIP_MODEL_DIR = {model_dir}')\n",
    "    \n",
    "    project_number = os.environ[\"CLOUD_ML_PROJECT_ID\"]\n",
    "    \n",
    "    vertex_ai.init(\n",
    "        project=project_number,\n",
    "        location='us-central1',\n",
    "        experiment=FLAGS.experiment_name\n",
    "    )\n",
    "\n",
    "    # Single Machine, single compute device\n",
    "    if FLAGS.strategy == 'single':\n",
    "        if tf.test.is_gpu_available():\n",
    "            strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "        else:\n",
    "            strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "        logging.info(\"Single device training\")\n",
    "    \n",
    "    # Single Machine, multiple compute device\n",
    "    elif FLAGS.strategy == 'mirrored':\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        logging.info(\"Mirrored Strategy distributed training\")\n",
    "    \n",
    "    # Multi Machine, multiple compute device\n",
    "    elif FLAGS.strategy == 'multiworker':\n",
    "        strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "        logging.info(\"Multi-worker Strategy distributed training\")\n",
    "        logging.info('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "   \n",
    "    # Single Machine, multiple TPU devices\n",
    "    elif FLAGS.strategy == 'tpu':\n",
    "        cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "        tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "        tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "        strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "        print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "    logging.info('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))\n",
    "    \n",
    "    if strategy.cluster_resolver:    \n",
    "        task_type, task_id = (strategy.cluster_resolver.task_type,\n",
    "                              strategy.cluster_resolver.task_id)\n",
    "    else:\n",
    "        task_type, task_id =(None, None)\n",
    "        \n",
    "    logging.info('task_type = {}'.format(task_type))\n",
    "    logging.info('task_id = {}'.format(task_id))\n",
    "    \n",
    "    global_batch_size = (\n",
    "        strategy.num_replicas_in_sync *\n",
    "        FLAGS.per_replica_batch_size\n",
    "    )\n",
    "    \n",
    "    train_ds, valid_ds, test_ds = create_input_pipelines(\n",
    "        FLAGS.training_data_path,\n",
    "        FLAGS.validation_data_path,\n",
    "        FLAGS.testing_data_path,\n",
    "        global_batch_size,\n",
    "        auto_shard_policy[FLAGS.auto_shard_policy])\n",
    "        \n",
    "    num_train_steps = FLAGS.steps_per_epoch * FLAGS.epochs\n",
    "    num_warmup_steps = int(0.1*num_train_steps)\n",
    "    init_lr = 3e-5\n",
    "    \n",
    "    with strategy.scope():\n",
    "        \n",
    "        model = build_classifier_model(TFHUB_HANDLE_PREPROCESS, TFHUB_HANDLE_ENCODER)\n",
    "        \n",
    "        loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        \n",
    "        metrics = tf.metrics.BinaryAccuracy()\n",
    "        \n",
    "        optimizer = optimization.create_optimizer(\n",
    "            init_lr=init_lr\n",
    "            , num_train_steps=num_train_steps\n",
    "            , num_warmup_steps=num_warmup_steps\n",
    "            , optimizer_type='adamw'\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer\n",
    "            , loss=loss\n",
    "            , metrics=metrics\n",
    "        )\n",
    "        \n",
    "    # Configure BackupAndRestore callback\n",
    "    if FLAGS.strategy == 'single':\n",
    "        callbacks = []\n",
    "        logging.info(\"No backup and restore\")\n",
    "    else:\n",
    "        backup_dir = '{}/backupandrestore'.format(FLAGS.job_dir)\n",
    "        callbacks = [tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=backup_dir)]\n",
    "        logging.info(f\"saved backup and restore t0: {backup_dir}\")\n",
    "    \n",
    "    # Configure TensorBoard callback on Chief\n",
    "    if _is_chief(task_type, task_id):\n",
    "        callbacks.append(\n",
    "            tf.keras.callbacks.TensorBoard(\n",
    "                log_dir=tb_dir\n",
    "                , update_freq='batch'\n",
    "                , histogram_freq=1\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    logging.info('Starting training ...')\n",
    "    \n",
    "    if _is_chief(task_type, task_id):\n",
    "        start_time = time.time()\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=train_ds\n",
    "        , validation_data=valid_ds\n",
    "        , steps_per_epoch=FLAGS.steps_per_epoch\n",
    "        , validation_steps=FLAGS.eval_steps\n",
    "        , epochs=FLAGS.epochs\n",
    "        , callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # ====================================================\n",
    "    # log Vertex Experiments\n",
    "    # ====================================================\n",
    "    SESSION_id = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=3))\n",
    "    \n",
    "    if _is_chief(task_type, task_id):\n",
    "        end_time = time.time()\n",
    "        # val metrics\n",
    "        val_keys = [v for v in history.history.keys()]\n",
    "        total_train_time = int((end_time - start_time) / 60)\n",
    "\n",
    "        metrics_dict = {\"total_train_time\": total_train_time}\n",
    "        logging.info(f\"total_train_time: {total_train_time}\")\n",
    "        _ = [metrics_dict.update({key: history.history[key][-1]}) for key in val_keys]\n",
    "    \n",
    "        logging.info(f\" task_type logging experiments: {task_type}\")\n",
    "        logging.info(f\" task_id logging experiments: {task_id}\")\n",
    "        logging.info(f\" logging data to experiment run: {FLAGS.experiment_run}-{SESSION_id}\")\n",
    "        \n",
    "        with vertex_ai.start_run(\n",
    "            f'{FLAGS.experiment_run}-{SESSION_id}', \n",
    "        ) as my_run:\n",
    "            \n",
    "            logging.info(f\"logging metrics...\")\n",
    "            my_run.log_metrics(metrics_dict)\n",
    "\n",
    "            logging.info(f\"logging metaparams...\")\n",
    "            my_run.log_params(\n",
    "                {\n",
    "                    \"epochs\": FLAGS.epochs,\n",
    "                    \"strategy\": FLAGS.strategy,\n",
    "                    \"per_replica_batch_size\": FLAGS.per_replica_batch_size,\n",
    "                    \"TRAIN_GPU\": FLAGS.TRAIN_GPU,\n",
    "                    \"TRAIN_NGPU\": FLAGS.TRAIN_NGPU,\n",
    "                    \"replica_count\": FLAGS.replica_count,\n",
    "                    \"reduction_cnt\": FLAGS.reduction_cnt,\n",
    "                    \"global_batch_size\": global_batch_size,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            vertex_ai.end_run()\n",
    "            logging.info(f\"EXPERIMENT RUN: '{FLAGS.experiment_run}-{SESSION_id}' has ended\")\n",
    "\n",
    "    if _is_chief(task_type, task_id):\n",
    "        # Copy tensorboard logs to GCS\n",
    "        # tb_logs = '{}/tb_logs'.format(FLAGS.job_dir)\n",
    "        # logging.info('Copying TensorBoard logs to: {}'.format(tb_logs))\n",
    "        # copy_tensorboard_logs(LOCAL_TB_FOLDER, tb_logs)\n",
    "        # saved_model_dir = '{}/saved_model'.format(model_dir)\n",
    "        logging.info('Training completed. Saving the trained model to: {}'.format(model_dir))\n",
    "        model.save(model_dir)\n",
    "    # else:\n",
    "    #     # saved_model_dir = model_dir\n",
    "    #     logging.info('Training completed. Saving the trained model to: {}'.format(model_dir))\n",
    "    #     model.save(model_dir)\n",
    "        \n",
    "    # Save trained model\n",
    "    # saved_model_dir = '{}/saved_model'.format(model_dir)\n",
    "    # logging.info('Training completed. Saving the trained model to: {}'.format(saved_model_dir))\n",
    "    # model.save(saved_model_dir)\n",
    "    #tf.saved_model.save(model, saved_model_dir)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "085d6600-0e5e-48cc-932d-b8cb01444e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGE = f'gcr.io/{PROJECT}/imdb_bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "290b6bc2-797c-400a-b814-167a59106e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile = f'''\n",
    "FROM {TRAIN_BASE_IMAGE}\n",
    "\n",
    "RUN pip install pip install tf-models-official==2.11.0 tensorflow-text==2.11.0\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "RUN apt update && apt -y install nvtop\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
    "'''\n",
    "\n",
    "with open('scripts/Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5893556b-691e-429d-b852-c32d29a0e1f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  19.46kB\n",
      "Step 1/6 : FROM us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-11:latest\n",
      " ---> 1fc7736bd93e\n",
      "Step 2/6 : RUN pip install pip install tf-models-official==2.11.0 tensorflow-text==2.11.0\n",
      " ---> Using cache\n",
      " ---> 21a04e0b97f8\n",
      "Step 3/6 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 9e7e18cb76dc\n",
      "Step 4/6 : COPY trainer /trainer\n",
      " ---> 8c4df82a0924\n",
      "Step 5/6 : RUN apt update && apt -y install nvtop\n",
      " ---> Running in f52dc9f3f7c9\n",
      "\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\u001b[0mGet:1 http://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:3 http://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [464 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [361 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [938 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [631 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [36.3 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [541 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [919 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [42.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [545 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1191 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [49.4 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [27.0 kB]\n",
      "Fetched 26.1 MB in 3s (7665 kB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "77 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\u001b[0mReading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  nvtop\n",
      "0 upgraded, 1 newly installed, 0 to remove and 77 not upgraded.\n",
      "Need to get 43.9 kB of archives.\n",
      "After this operation, 106 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvtop amd64 1.2.2-1 [43.9 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 43.9 kB in 0s (97.4 kB/s)\n",
      "Selecting previously unselected package nvtop.\n",
      "(Reading database ... 74622 files and directories currently installed.)\n",
      "Preparing to unpack .../nvtop_1.2.2-1_amd64.deb ...\n",
      "Unpacking nvtop (1.2.2-1) ...\n",
      "Setting up nvtop (1.2.2-1) ...\n",
      "Removing intermediate container f52dc9f3f7c9\n",
      " ---> 4391d289c83d\n",
      "Step 6/6 : ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
      " ---> Running in 4287a8acfe71\n",
      "Removing intermediate container 4287a8acfe71\n",
      " ---> 6eaf6736c7a6\n",
      "Successfully built 6eaf6736c7a6\n",
      "Successfully tagged gcr.io/hybrid-vertex/imdb_bert:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t {TRAIN_IMAGE} scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09fd8567-d1e4-4c1d-bc2f-acdbf1664b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/hybrid-vertex/imdb_bert]\n",
      "\n",
      "\u001b[1B547609c0: Preparing \n",
      "\u001b[1B43e55906: Preparing \n",
      "\u001b[1B65c47b32: Preparing \n",
      "\u001b[1B95c7b436: Preparing \n",
      "\u001b[1Bf663075e: Preparing \n",
      "\u001b[1B7fbea69f: Preparing \n",
      "\u001b[1Bdcb6c992: Preparing \n",
      "\u001b[1B57d3600a: Preparing \n",
      "\u001b[1B98aef500: Preparing \n",
      "\u001b[1B937e6451: Preparing \n",
      "\u001b[1Bf16690a3: Preparing \n",
      "\u001b[1B0ba8f8e0: Preparing \n",
      "\u001b[1B061c8df0: Preparing \n",
      "\u001b[1B20bdc5a8: Preparing \n",
      "\u001b[1B9623cc67: Preparing \n",
      "\u001b[1Bf5f47ef7: Preparing \n",
      "\u001b[1Be3a670db: Preparing \n",
      "\u001b[1Bab0a5210: Preparing \n",
      "\u001b[1B27b973c2: Preparing \n",
      "\u001b[1B003a8778: Preparing \n",
      "\u001b[1B6eb0eac1: Preparing \n",
      "\u001b[1Ba842d5cf: Preparing \n",
      "\u001b[1B7c820400: Preparing \n",
      "\u001b[1B2eabba29: Preparing \n",
      "\u001b[1B9e83e652: Preparing \n",
      "\u001b[1B8f4121e3: Preparing \n",
      "\u001b[20B7d3600a: Waiting g \n",
      "\u001b[20B8aef500: Waiting g \n",
      "\u001b[1Bd7cd1026: Preparing \n",
      "\u001b[21B37e6451: Waiting g \n",
      "\u001b[1B06a133b8: Preparing \n",
      "\u001b[22B16690a3: Waiting g \n",
      "\u001b[1Bd1f80fca: Preparing \n",
      "\u001b[1Bf0edb23d: Preparing \n",
      "\u001b[35B47609c0: Pushed   44.08MB/44.04MB\u001b[30A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2Klatest: digest: sha256:72723df8316eecfcf2b54e4021ea04ea508cdd659c04e75eeab1f44f8d2e262e size: 8284\n"
     ]
    }
   ],
   "source": [
    "! docker push {TRAIN_IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d589c-4f86-4db6-bbf1-f60020a767d4",
   "metadata": {},
   "source": [
    "## Submitting training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39b83c1c-5a25-4071-bbcf-c7f9b4919273",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f49f512-71c3-4cdc-bb2f-7ebf0186355b",
   "metadata": {},
   "source": [
    "## 1 Replica, 1 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998250ad-48d0-4334-be4c-050fbab84914",
   "metadata": {},
   "source": [
    "### set Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c18b1b2f-156f-46e3-897f-f9727468d258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: jtv7-bert-tune\n",
      "RUN_NAME: run-20230620-220732\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EXPERIMENT_PREFIX = 'bert'\n",
    "EXPERIMENT_NAME=f'{PREFIX}-bert-tune'\n",
    "RUN_NAME = f'run-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79b4c3fa-7c2e-47c4-9e2b-0a6732b20c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE_TYPE          : n1-standard-16\n",
      "TRAIN_GPU             : NVIDIA_TESLA_T4\n",
      "TRAIN_NGPU            : 1\n",
      "REPLICA_COUNT         : 1\n",
      "DISTRIBUTION_STRATEGY : single\n"
     ]
    }
   ],
   "source": [
    "MACHINE_TYPE = 'n1-standard-16'\n",
    "TRAIN_GPU, TRAIN_NGPU = ('NVIDIA_TESLA_T4', 1) # NVIDIA_TESLA_T4 NVIDIA_TESLA_V100\n",
    "\n",
    "REPLICA_COUNT = 1\n",
    "DISTRIBUTION_STRATEGY = \"single\" # single, mirrored, multiworker, tpu\n",
    "\n",
    "print(f\"MACHINE_TYPE          : {MACHINE_TYPE}\")\n",
    "print(f\"TRAIN_GPU             : {TRAIN_GPU}\")\n",
    "print(f\"TRAIN_NGPU            : {TRAIN_NGPU}\")\n",
    "print(f\"REPLICA_COUNT         : {REPLICA_COUNT}\")\n",
    "print(f\"DISTRIBUTION_STRATEGY : {DISTRIBUTION_STRATEGY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b5362d2-6f4e-49d7-9d6a-9a548bfe722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--epochs=10',\n",
      "                              '--steps_per_epoch=200',\n",
      "                              '--eval_steps=50',\n",
      "                              '--per_replica_batch_size=32',\n",
      "                              '--training_data_path=gs://jtv7-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/train',\n",
      "                              '--validation_data_path=gs://jtv7-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/valid',\n",
      "                              '--testing_data_path=gs://jtv7-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/test',\n",
      "                              '--job_dir=gs://jtv7-hybrid-vertex-bucket/jobs/job-20230620220736',\n",
      "                              '--strategy=single',\n",
      "                              '--auto_shard_policy=auto',\n",
      "                              '--job_id=job-20230620220736',\n",
      "                              '--TRAIN_GPU=NVIDIA_TESLA_T4',\n",
      "                              '--TRAIN_NGPU=1',\n",
      "                              '--reduction_cnt=0',\n",
      "                              '--replica_count=1',\n",
      "                              '--experiment_name=jtv7-bert-tune',\n",
      "                              '--experiment_run=run-20230620-220732'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/imdb_bert'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-16'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 200\n",
    "eval_steps = 50\n",
    "PER_REPLICA_BATCH_SIZE = 32\n",
    "\n",
    "REDUCTION_SERVER_COUNT = 0\n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "\n",
    "training_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/train'\n",
    "validation_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/valid'\n",
    "testing_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/test'\n",
    "\n",
    "job_id = f'job-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'.format()\n",
    "job_dir = f'{STAGING_BUCKET}/jobs/{job_id}'\n",
    "\n",
    "WORKER_ARGS = [\n",
    "    \"--epochs=\" + str(epochs)\n",
    "    , \"--steps_per_epoch=\" + str(steps_per_epoch)\n",
    "    , \"--eval_steps=\" + str(eval_steps)\n",
    "    , \"--per_replica_batch_size=\" + str(PER_REPLICA_BATCH_SIZE)\n",
    "    , \"--training_data_path=\" + training_data_path\n",
    "    , \"--validation_data_path=\" + validation_data_path\n",
    "    , \"--testing_data_path=\" + testing_data_path\n",
    "    , \"--job_dir=\" + job_dir\n",
    "    , f\"--strategy={DISTRIBUTION_STRATEGY}\"\n",
    "    , \"--auto_shard_policy=auto\" #data\n",
    "    , f\"--job_id={job_id}\"\n",
    "    , f\"--TRAIN_GPU={TRAIN_GPU}\"\n",
    "    , f\"--TRAIN_NGPU={TRAIN_NGPU}\"\n",
    "    , f\"--reduction_cnt={REDUCTION_SERVER_COUNT}\"\n",
    "    , f\"--replica_count={REPLICA_COUNT}\"\n",
    "    , f\"--experiment_name={EXPERIMENT_NAME}\"\n",
    "    , f\"--experiment_run={RUN_NAME}\"\n",
    "]\n",
    "\n",
    "from utils import workerpool_specs\n",
    "\n",
    "WORKER_POOL_SPECS = workerpool_specs.prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=WORKER_ARGS,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    "    accelerator_type=TRAIN_GPU,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bfbe0a9-3d5c-4895-9039-55858aa2c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/934903580331/locations/us-central1/tensorboards/949934065933352960\n"
     ]
    }
   ],
   "source": [
    "vertex_ai_tb = vertex_ai.Tensorboard.create()\n",
    "TENSORBOARD = vertex_ai_tb.gca_resource.name\n",
    "print(TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19c24174-dec7-4d12-a24a-cee5edbe8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    experiment=EXPERIMENT_NAME\n",
    "    # , experiment_tensorboard=vertex_ai_tb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c740910e-f137-4d82-852c-f12a9df3d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_job = vertex_ai.CustomJob(\n",
    "    display_name=f'imdb-bert-{RUN_NAME}-{DISTRIBUTION_STRATEGY}-{REPLICA_COUNT}-{TRAIN_NGPU}',\n",
    "    worker_pool_specs=WORKER_POOL_SPECS,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e98565e-12df-42bc-a37b-fd1669453b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_job.run(\n",
    "    sync=False\n",
    "    , service_account=VERTEX_SA\n",
    "    , tensorboard=TENSORBOARD\n",
    "    , restart_job_on_worker_restart=False\n",
    "    , enable_web_access=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b889e3b7-0924-4a95-9db2-a600fc8fddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: imdb-bert-run-20230620-220732-single-1-1\n",
      "Job Resource Name: projects/934903580331/locations/us-central1/customJobs/12692624792092672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job Name: {custom_job.display_name}\")\n",
    "print(f\"Job Resource Name: {custom_job.resource_name}\\n\")\n",
    "# print(f\"Check training progress at {custom_job._dashboard_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7585ba6c-ce57-408e-abaf-c4e77b9a8493",
   "metadata": {},
   "source": [
    "## 1 Replica, 2 GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6bc57-446c-44fc-881e-b80ec2a4d00a",
   "metadata": {},
   "source": [
    "### set Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d2d5f13-cec0-466a-8cbd-a43999f18777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: jtv7-bert-tune\n",
      "RUN_NAME: run-20230620-220830\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = f'run-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e7cd69d-9eaf-421e-8569-872c1cfab657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE_TYPE          : n1-standard-32\n",
      "TRAIN_GPU             : NVIDIA_TESLA_T4\n",
      "TRAIN_NGPU            : 2\n",
      "REPLICA_COUNT         : 1\n",
      "DISTRIBUTION_STRATEGY : mirrored\n"
     ]
    }
   ],
   "source": [
    "MACHINE_TYPE = 'n1-standard-32'\n",
    "TRAIN_GPU, TRAIN_NGPU = ('NVIDIA_TESLA_T4', 2) # NVIDIA_TESLA_T4 NVIDIA_TESLA_V100\n",
    "\n",
    "REPLICA_COUNT = 1\n",
    "DISTRIBUTION_STRATEGY = \"mirrored\" # single, mirrored, multiworker, tpu\n",
    "\n",
    "print(f\"MACHINE_TYPE          : {MACHINE_TYPE}\")\n",
    "print(f\"TRAIN_GPU             : {TRAIN_GPU}\")\n",
    "print(f\"TRAIN_NGPU            : {TRAIN_NGPU}\")\n",
    "print(f\"REPLICA_COUNT         : {REPLICA_COUNT}\")\n",
    "print(f\"DISTRIBUTION_STRATEGY : {DISTRIBUTION_STRATEGY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87ac4831-19e0-4819-a301-dfc33c088baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--epochs=10',\n",
      "                              '--steps_per_epoch=200',\n",
      "                              '--eval_steps=50',\n",
      "                              '--per_replica_batch_size=32',\n",
      "                              '--training_data_path=gs://jtv7-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/train',\n",
      "                              '--validation_data_path=gs://jtv7-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/valid',\n",
      "                              '--testing_data_path=gs://jtv7-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/test',\n",
      "                              '--job_dir=gs://jtv7-hybrid-vertex-bucket/jobs/job-20230620220833',\n",
      "                              '--strategy=mirrored',\n",
      "                              '--auto_shard_policy=auto',\n",
      "                              '--job_id=job-20230620220833',\n",
      "                              '--TRAIN_GPU=NVIDIA_TESLA_T4',\n",
      "                              '--TRAIN_NGPU=2',\n",
      "                              '--reduction_cnt=0',\n",
      "                              '--replica_count=1',\n",
      "                              '--experiment_name=jtv7-bert-tune',\n",
      "                              '--experiment_run=run-20230620-220830'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/imdb_bert'},\n",
      "  'machine_spec': {'accelerator_count': 2,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-32'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 200\n",
    "eval_steps = 50\n",
    "# reduction_serv='False'\n",
    "PER_REPLICA_BATCH_SIZE = 32\n",
    "\n",
    "REDUCTION_SERVER_COUNT = 0\n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "\n",
    "training_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/train'\n",
    "validation_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/valid'\n",
    "testing_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/test'\n",
    "\n",
    "job_id = f'job-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'.format()\n",
    "job_dir = f'{STAGING_BUCKET}/jobs/{job_id}'\n",
    "\n",
    "WORKER_ARGS = [\n",
    "    \"--epochs=\" + str(epochs)\n",
    "    , \"--steps_per_epoch=\" + str(steps_per_epoch)\n",
    "    , \"--eval_steps=\" + str(eval_steps)\n",
    "    , \"--per_replica_batch_size=\" + str(PER_REPLICA_BATCH_SIZE)\n",
    "    , \"--training_data_path=\" + training_data_path\n",
    "    , \"--validation_data_path=\" + validation_data_path\n",
    "    , \"--testing_data_path=\" + testing_data_path\n",
    "    , \"--job_dir=\" + job_dir\n",
    "    , f\"--strategy={DISTRIBUTION_STRATEGY}\"\n",
    "    , \"--auto_shard_policy=auto\" #data\n",
    "    , f\"--job_id={job_id}\"\n",
    "    , f\"--TRAIN_GPU={TRAIN_GPU}\"\n",
    "    , f\"--TRAIN_NGPU={TRAIN_NGPU}\"\n",
    "    , f\"--reduction_cnt={REDUCTION_SERVER_COUNT}\"\n",
    "    , f\"--replica_count={REPLICA_COUNT}\"\n",
    "    , f\"--experiment_name={EXPERIMENT_NAME}\"\n",
    "    , f\"--experiment_run={RUN_NAME}\"\n",
    "]\n",
    "\n",
    "from utils import workerpool_specs\n",
    "\n",
    "WORKER_POOL_SPECS = workerpool_specs.prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=WORKER_ARGS,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    "    accelerator_type=TRAIN_GPU,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7ff735b-fa86-424b-88a4-219c3d779ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/934903580331/locations/us-central1/tensorboards/6822627980024479744\n"
     ]
    }
   ],
   "source": [
    "vertex_ai_tb = vertex_ai.Tensorboard.create()\n",
    "TENSORBOARD = vertex_ai_tb.gca_resource.name\n",
    "print(TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a80ea24b-d7a5-4d1f-ad60-3691a56014ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    experiment=EXPERIMENT_NAME\n",
    "    # , experiment_tensorboard=vertex_ai_tb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0453f249-a24e-42a5-aa08-7bfe011e2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_m_job = vertex_ai.CustomJob(\n",
    "    display_name=f'imdb-bert-{RUN_NAME}-{DISTRIBUTION_STRATEGY}-{REPLICA_COUNT}-{TRAIN_NGPU}',\n",
    "    worker_pool_specs=WORKER_POOL_SPECS,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a79b3764-85e8-462b-997b-89c29040785d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_m_job.run(\n",
    "    sync=False\n",
    "    , service_account=VERTEX_SA\n",
    "    , tensorboard=TENSORBOARD\n",
    "    , restart_job_on_worker_restart=False\n",
    "    , enable_web_access=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40c56959-bda6-4998-8e2d-a832ff1880c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: imdb-bert-run-20230620-220830-mirrored-1-2\n",
      "Job Resource Name: projects/934903580331/locations/us-central1/customJobs/1140281381494980608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job Name: {custom_m_job.display_name}\")\n",
    "print(f\"Job Resource Name: {custom_m_job.resource_name}\\n\")\n",
    "# print(f\"Check training progress at {custom_job._dashboard_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6abfa-2808-4cdb-8171-9f70274c44b0",
   "metadata": {},
   "source": [
    "## 2 Replicas, 1 GPU each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a58ba5-85b0-4408-9178-bfd110a1115f",
   "metadata": {},
   "source": [
    "> Now increase `replica_count` from 1 to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b687e5d6-5287-46f4-9347-ef5ad14df96f",
   "metadata": {},
   "source": [
    "### set Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0e3616b-db10-4d88-84c2-e71ede086ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: jtv6-bert-tune\n",
      "RUN_NAME: run-20230620-175546\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = f'run-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19cccf96-015a-4bde-a3d4-9ecc316b7700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE_TYPE          : n1-standard-8\n",
      "TRAIN_GPU             : NVIDIA_TESLA_V100\n",
      "TRAIN_NGPU            : 1\n",
      "REPLICA_COUNT         : 2\n",
      "DISTRIBUTION_STRATEGY : multiworker\n"
     ]
    }
   ],
   "source": [
    "MACHINE_TYPE = 'n1-standard-16'\n",
    "TRAIN_GPU, TRAIN_NGPU = ('NVIDIA_TESLA_T4', 1) # NVIDIA_TESLA_T4 NVIDIA_TESLA_V100\n",
    "\n",
    "REPLICA_COUNT = 2\n",
    "DISTRIBUTION_STRATEGY = \"multiworker\" # single, mirrored, multiworker, tpu\n",
    "\n",
    "print(f\"MACHINE_TYPE          : {MACHINE_TYPE}\")\n",
    "print(f\"TRAIN_GPU             : {TRAIN_GPU}\")\n",
    "print(f\"TRAIN_NGPU            : {TRAIN_NGPU}\")\n",
    "print(f\"REPLICA_COUNT         : {REPLICA_COUNT}\")\n",
    "print(f\"DISTRIBUTION_STRATEGY : {DISTRIBUTION_STRATEGY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "726e5b05-102e-4f3c-be16-a025cbb452ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--epochs=25',\n",
      "                              '--steps_per_epoch=200',\n",
      "                              '--eval_steps=50',\n",
      "                              '--per_replica_batch_size=32',\n",
      "                              '--training_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/train',\n",
      "                              '--validation_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/valid',\n",
      "                              '--testing_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/test',\n",
      "                              '--job_dir=gs://jtv6-hybrid-vertex-bucket/jobs/job-20230620175548',\n",
      "                              '--strategy=multiworker',\n",
      "                              '--auto_shard_policy=data',\n",
      "                              '--job_id=job-20230620175548',\n",
      "                              '--TRAIN_GPU=NVIDIA_TESLA_V100',\n",
      "                              '--TRAIN_NGPU=1',\n",
      "                              '--reduction_cnt=0',\n",
      "                              '--replica_count=2',\n",
      "                              '--experiment_name=jtv6-bert-tune',\n",
      "                              '--experiment_run=run-20230620-175546'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/imdb_bert'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_V100',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1},\n",
      " {'container_spec': {'args': ['--epochs=25',\n",
      "                              '--steps_per_epoch=200',\n",
      "                              '--eval_steps=50',\n",
      "                              '--per_replica_batch_size=32',\n",
      "                              '--training_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/train',\n",
      "                              '--validation_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/valid',\n",
      "                              '--testing_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/test',\n",
      "                              '--job_dir=gs://jtv6-hybrid-vertex-bucket/jobs/job-20230620175548',\n",
      "                              '--strategy=multiworker',\n",
      "                              '--auto_shard_policy=data',\n",
      "                              '--job_id=job-20230620175548',\n",
      "                              '--TRAIN_GPU=NVIDIA_TESLA_V100',\n",
      "                              '--TRAIN_NGPU=1',\n",
      "                              '--reduction_cnt=0',\n",
      "                              '--replica_count=2',\n",
      "                              '--experiment_name=jtv6-bert-tune',\n",
      "                              '--experiment_run=run-20230620-175546'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/imdb_bert'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_V100',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 200\n",
    "eval_steps = 50\n",
    "# reduction_serv='False'\n",
    "PER_REPLICA_BATCH_SIZE = 32\n",
    "\n",
    "REDUCTION_SERVER_COUNT = 0\n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "\n",
    "training_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/train'\n",
    "validation_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/valid'\n",
    "testing_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/test'\n",
    "job_id = 'job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "job_dir = f'{STAGING_BUCKET}/jobs/{job_id}'\n",
    "\n",
    "WORKER_ARGS = [\n",
    "    \"--epochs=\" + str(epochs)\n",
    "    , \"--steps_per_epoch=\" + str(steps_per_epoch)\n",
    "    , \"--eval_steps=\" + str(eval_steps)\n",
    "    , \"--per_replica_batch_size=\" + str(PER_REPLICA_BATCH_SIZE)\n",
    "    , \"--training_data_path=\" + training_data_path\n",
    "    , \"--validation_data_path=\" + validation_data_path\n",
    "    , \"--testing_data_path=\" + testing_data_path\n",
    "    , \"--job_dir=\" + job_dir\n",
    "    , f\"--strategy={DISTRIBUTION_STRATEGY}\"\n",
    "    , \"--auto_shard_policy=auto\" # data\n",
    "    , f\"--job_id={job_id}\"\n",
    "    , f\"--TRAIN_GPU={TRAIN_GPU}\"\n",
    "    , f\"--TRAIN_NGPU={TRAIN_NGPU}\"\n",
    "    , f\"--reduction_cnt={REDUCTION_SERVER_COUNT}\"\n",
    "    , f\"--replica_count={REPLICA_COUNT}\"\n",
    "    , f\"--experiment_name={EXPERIMENT_NAME}\"\n",
    "    , f\"--experiment_run={RUN_NAME}\"\n",
    "]\n",
    "\n",
    "from utils import workerpool_specs\n",
    "\n",
    "WORKER_POOL_SPECS = workerpool_specs.prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=WORKER_ARGS,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    "    accelerator_type=TRAIN_GPU,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30345523-3c20-473f-85a4-4a61963c2072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/934903580331/locations/us-central1/tensorboards/6689771791017050112\n"
     ]
    }
   ],
   "source": [
    "vertex_ai_tb = vertex_ai.Tensorboard.create()\n",
    "TENSORBOARD = vertex_ai_tb.gca_resource.name\n",
    "print(TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89db16c0-0027-4fb2-accb-3433add133e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    experiment=EXPERIMENT_NAME\n",
    "    # , experiment_tensorboard=vertex_ai_tb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3386f043-bf34-4a9e-b20a-3c124a7be353",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_mm_job = vertex_ai.CustomJob(\n",
    "    display_name=f'imdb-bert-{RUN_NAME}-{DISTRIBUTION_STRATEGY}-{REPLICA_COUNT}-{TRAIN_NGPU}',\n",
    "    worker_pool_specs=WORKER_POOL_SPECS,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2e33d75-c508-420c-a295-1ff5f7ed95e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_mm_job.run(\n",
    "    sync=False\n",
    "    , service_account=VERTEX_SA\n",
    "    , tensorboard=TENSORBOARD\n",
    "    , restart_job_on_worker_restart=False\n",
    "    , enable_web_access=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2a452a2-90fd-48c5-bd88-6ddf2f308911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: imdb-bert-run-20230620-175546-multiworker-2-1\n",
      "Job Resource Name: projects/934903580331/locations/us-central1/customJobs/241760479276433408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job Name: {custom_mm_job.display_name}\")\n",
    "print(f\"Job Resource Name: {custom_mm_job.resource_name}\\n\")\n",
    "# print(f\"Check training progress at {custom_m_job._dashboard_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bf1aa-7a2e-4e5c-90a4-4810382c6072",
   "metadata": {},
   "source": [
    "## 2 Replicas, 1 GPU each + Reduction Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41022c94-5805-4e8d-948e-c09177ad50cb",
   "metadata": {},
   "source": [
    "### set Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2ba2172-1102-413a-b541-b9e23e757da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: jtv6-bert-tune\n",
      "RUN_NAME: run-20230620-175824\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = f'run-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a7ff1cb-8554-45d3-a3fb-6ec46a797630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE_TYPE          : n1-standard-8\n",
      "TRAIN_GPU             : NVIDIA_TESLA_V100\n",
      "TRAIN_NGPU            : 1\n",
      "REPLICA_COUNT         : 2\n",
      "DISTRIBUTION_STRATEGY : multiworker\n"
     ]
    }
   ],
   "source": [
    "MACHINE_TYPE = 'n1-standard-16'\n",
    "TRAIN_GPU, TRAIN_NGPU = ('NVIDIA_TESLA_T4', 1) # NVIDIA_TESLA_T4 NVIDIA_TESLA_V100\n",
    "\n",
    "REPLICA_COUNT = 2\n",
    "DISTRIBUTION_STRATEGY = \"multiworker\" # single, mirrored, multiworker, tpu\n",
    "\n",
    "print(f\"MACHINE_TYPE          : {MACHINE_TYPE}\")\n",
    "print(f\"TRAIN_GPU             : {TRAIN_GPU}\")\n",
    "print(f\"TRAIN_NGPU            : {TRAIN_NGPU}\")\n",
    "print(f\"REPLICA_COUNT         : {REPLICA_COUNT}\")\n",
    "print(f\"DISTRIBUTION_STRATEGY : {DISTRIBUTION_STRATEGY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6222a212-5d29-4036-b07b-a9c4cb33f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--epochs=25',\n",
      "                              '--steps_per_epoch=200',\n",
      "                              '--eval_steps=50',\n",
      "                              '--per_replica_batch_size=32',\n",
      "                              '--training_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/train',\n",
      "                              '--validation_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/valid',\n",
      "                              '--testing_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/test',\n",
      "                              '--job_dir=gs://jtv6-hybrid-vertex-bucket/jobs/job-20230620175832',\n",
      "                              '--strategy=multiworker',\n",
      "                              '--auto_shard_policy=data',\n",
      "                              '--job_id=job-20230620175832',\n",
      "                              '--TRAIN_GPU=NVIDIA_TESLA_V100',\n",
      "                              '--TRAIN_NGPU=1',\n",
      "                              '--reduction_cnt=4',\n",
      "                              '--replica_count=2',\n",
      "                              '--experiment_name=jtv6-bert-tune',\n",
      "                              '--experiment_run=run-20230620-175824'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/imdb_bert'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_V100',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1},\n",
      " {'container_spec': {'args': ['--epochs=25',\n",
      "                              '--steps_per_epoch=200',\n",
      "                              '--eval_steps=50',\n",
      "                              '--per_replica_batch_size=32',\n",
      "                              '--training_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/train',\n",
      "                              '--validation_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/valid',\n",
      "                              '--testing_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/test',\n",
      "                              '--job_dir=gs://jtv6-hybrid-vertex-bucket/jobs/job-20230620175832',\n",
      "                              '--strategy=multiworker',\n",
      "                              '--auto_shard_policy=data',\n",
      "                              '--job_id=job-20230620175832',\n",
      "                              '--TRAIN_GPU=NVIDIA_TESLA_V100',\n",
      "                              '--TRAIN_NGPU=1',\n",
      "                              '--reduction_cnt=4',\n",
      "                              '--replica_count=2',\n",
      "                              '--experiment_name=jtv6-bert-tune',\n",
      "                              '--experiment_run=run-20230620-175824'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/imdb_bert'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_V100',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1},\n",
      " {'container_spec': {'image_uri': 'us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest'},\n",
      "  'machine_spec': {'machine_type': 'n1-highcpu-16'},\n",
      "  'replica_count': 4}]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 200\n",
    "eval_steps = 50\n",
    "# reduction_serv='False'\n",
    "PER_REPLICA_BATCH_SIZE = 32\n",
    "\n",
    "DISTRIBUTION_STRATEGY = \"multiworker\" # single, mirrored, multiworker, tpu\n",
    "\n",
    "REDUCTION_SERVER_COUNT = 4\n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "\n",
    "training_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/train'\n",
    "validation_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/valid'\n",
    "testing_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/test'\n",
    "job_id = 'job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "job_dir = f'{STAGING_BUCKET}/jobs/{job_id}'\n",
    "\n",
    "WORKER_ARGS = [\n",
    "    \"--epochs=\" + str(epochs)\n",
    "    , \"--steps_per_epoch=\" + str(steps_per_epoch)\n",
    "    , \"--eval_steps=\" + str(eval_steps)\n",
    "    , \"--per_replica_batch_size=\" + str(PER_REPLICA_BATCH_SIZE)\n",
    "    , \"--training_data_path=\" + training_data_path\n",
    "    , \"--validation_data_path=\" + validation_data_path\n",
    "    , \"--testing_data_path=\" + testing_data_path\n",
    "    , \"--job_dir=\" + job_dir\n",
    "    , f\"--strategy={DISTRIBUTION_STRATEGY}\"\n",
    "    , \"--auto_shard_policy=auto\" # data\n",
    "    , f\"--job_id={job_id}\"\n",
    "    , f\"--TRAIN_GPU={TRAIN_GPU}\"\n",
    "    , f\"--TRAIN_NGPU={TRAIN_NGPU}\"\n",
    "    , f\"--reduction_cnt={REDUCTION_SERVER_COUNT}\"\n",
    "    , f\"--replica_count={REPLICA_COUNT}\"\n",
    "    , f\"--experiment_name={EXPERIMENT_NAME}\"\n",
    "    , f\"--experiment_run={RUN_NAME}\"\n",
    "]\n",
    "\n",
    "from utils import workerpool_specs\n",
    "\n",
    "WORKER_POOL_SPECS = workerpool_specs.prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=WORKER_ARGS,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    "    accelerator_type=TRAIN_GPU,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fcd26393-3755-4cf7-b19a-6d5560c0d00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/934903580331/locations/us-central1/tensorboards/2853830808404230144\n"
     ]
    }
   ],
   "source": [
    "vertex_ai_tb = vertex_ai.Tensorboard.create()\n",
    "TENSORBOARD = vertex_ai_tb.gca_resource.name\n",
    "print(TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "feca486a-bfff-4c7f-8573-c113873f7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    experiment=EXPERIMENT_NAME\n",
    "    # , experiment_tensorboard=vertex_ai_tb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e2b5534-58aa-4ade-91c5-911448ff3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_mmr_job = vertex_ai.CustomJob(\n",
    "    display_name=f'imdb-bert-{RUN_NAME}-{DISTRIBUTION_STRATEGY}-{REPLICA_COUNT}-{TRAIN_NGPU}-r',\n",
    "    worker_pool_specs=WORKER_POOL_SPECS,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62af2d8c-5e4c-4adc-9cd8-0602883d5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_mmr_job.run(\n",
    "    sync=False\n",
    "    , service_account=VERTEX_SA\n",
    "    , tensorboard=TENSORBOARD\n",
    "    , restart_job_on_worker_restart=False\n",
    "    , enable_web_access=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90747067-f6d8-48ba-895e-a5f4c0c9f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: imdb-bert-run-20230620-175824-multiworker-2-1-r\n",
      "Job Resource Name: projects/934903580331/locations/us-central1/customJobs/961210519748870144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job Name: {custom_mmr_job.display_name}\")\n",
    "print(f\"Job Resource Name: {custom_mmr_job.resource_name}\\n\")\n",
    "# print(f\"Check training progress at {custom_m_job._dashboard_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32e8af-7d24-4cd1-8324-54f41b971d36",
   "metadata": {},
   "source": [
    "## 2 Replicas, 2 GPUs each + Reduction Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5eb66-b7d9-4716-b3a4-f5e89c764223",
   "metadata": {},
   "source": [
    "### set Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc5e0fc3-a165-4051-95eb-3634ad0ae4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: jtv6-bert-tune\n",
      "RUN_NAME: run-20230620-180730\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = f'run-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aca0c2a9-9de4-4e9d-adc9-e5fc9f161d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE_TYPE          : n1-standard-16\n",
      "TRAIN_GPU             : NVIDIA_TESLA_T4\n",
      "TRAIN_NGPU            : 2\n",
      "REPLICA_COUNT         : 2\n",
      "DISTRIBUTION_STRATEGY : multiworker\n"
     ]
    }
   ],
   "source": [
    "# MACHINE_TYPE = 'a2-highgpu-2g'\n",
    "# TRAIN_GPU, TRAIN_NGPU = ('NVIDIA_TESLA_A100', 2)\n",
    "\n",
    "MACHINE_TYPE = 'n1-standard-16'\n",
    "TRAIN_GPU, TRAIN_NGPU = ('NVIDIA_TESLA_T4', 2)\n",
    "\n",
    "REPLICA_COUNT = 2\n",
    "DISTRIBUTION_STRATEGY = \"multiworker\" # single, mirrored, multiworker, tpu\n",
    "\n",
    "print(f\"MACHINE_TYPE          : {MACHINE_TYPE}\")\n",
    "print(f\"TRAIN_GPU             : {TRAIN_GPU}\")\n",
    "print(f\"TRAIN_NGPU            : {TRAIN_NGPU}\")\n",
    "print(f\"REPLICA_COUNT         : {REPLICA_COUNT}\")\n",
    "print(f\"DISTRIBUTION_STRATEGY : {DISTRIBUTION_STRATEGY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82326847-5b3e-48ec-87ce-d447f965ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--epochs=25',\n",
      "                              '--steps_per_epoch=200',\n",
      "                              '--eval_steps=50',\n",
      "                              '--per_replica_batch_size=32',\n",
      "                              '--training_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/train',\n",
      "                              '--validation_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/valid',\n",
      "                              '--testing_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/test',\n",
      "                              '--job_dir=gs://jtv6-hybrid-vertex-bucket/jobs/job-20230620180732',\n",
      "                              '--strategy=multiworker',\n",
      "                              '--auto_shard_policy=data',\n",
      "                              '--job_id=job-20230620180732',\n",
      "                              '--TRAIN_GPU=NVIDIA_TESLA_T4',\n",
      "                              '--TRAIN_NGPU=2',\n",
      "                              '--reduction_cnt=4',\n",
      "                              '--replica_count=2',\n",
      "                              '--experiment_name=jtv6-bert-tune',\n",
      "                              '--experiment_run=run-20230620-180730'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/imdb_bert'},\n",
      "  'machine_spec': {'accelerator_count': 2,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-16'},\n",
      "  'replica_count': 1},\n",
      " {'container_spec': {'args': ['--epochs=25',\n",
      "                              '--steps_per_epoch=200',\n",
      "                              '--eval_steps=50',\n",
      "                              '--per_replica_batch_size=32',\n",
      "                              '--training_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/train',\n",
      "                              '--validation_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/valid',\n",
      "                              '--testing_data_path=gs://jtv6-hybrid-vertex-bucket/bert-finetuning/imdb/tfrecords/test',\n",
      "                              '--job_dir=gs://jtv6-hybrid-vertex-bucket/jobs/job-20230620180732',\n",
      "                              '--strategy=multiworker',\n",
      "                              '--auto_shard_policy=data',\n",
      "                              '--job_id=job-20230620180732',\n",
      "                              '--TRAIN_GPU=NVIDIA_TESLA_T4',\n",
      "                              '--TRAIN_NGPU=2',\n",
      "                              '--reduction_cnt=4',\n",
      "                              '--replica_count=2',\n",
      "                              '--experiment_name=jtv6-bert-tune',\n",
      "                              '--experiment_run=run-20230620-180730'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/imdb_bert'},\n",
      "  'machine_spec': {'accelerator_count': 2,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-16'},\n",
      "  'replica_count': 1},\n",
      " {'container_spec': {'image_uri': 'us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest'},\n",
      "  'machine_spec': {'machine_type': 'n1-highcpu-16'},\n",
      "  'replica_count': 4}]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 200\n",
    "eval_steps = 50\n",
    "PER_REPLICA_BATCH_SIZE = 32\n",
    "\n",
    "REDUCTION_SERVER_COUNT = 4\n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "\n",
    "training_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/train'\n",
    "validation_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/valid'\n",
    "testing_data_path = f'{STAGING_BUCKET}/bert-finetuning/imdb/tfrecords/test'\n",
    "job_id = 'job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "job_dir = f'{STAGING_BUCKET}/jobs/{job_id}'\n",
    "\n",
    "WORKER_ARGS = [\n",
    "    \"--epochs=\" + str(epochs)\n",
    "    , \"--steps_per_epoch=\" + str(steps_per_epoch)\n",
    "    , \"--eval_steps=\" + str(eval_steps)\n",
    "    , \"--per_replica_batch_size=\" + str(PER_REPLICA_BATCH_SIZE)\n",
    "    , \"--training_data_path=\" + training_data_path\n",
    "    , \"--validation_data_path=\" + validation_data_path\n",
    "    , \"--testing_data_path=\" + testing_data_path\n",
    "    , \"--job_dir=\" + job_dir\n",
    "    , f\"--strategy={DISTRIBUTION_STRATEGY}\"\n",
    "    , \"--auto_shard_policy=auto\" # data\n",
    "    , f\"--job_id={job_id}\"\n",
    "    , f\"--TRAIN_GPU={TRAIN_GPU}\"\n",
    "    , f\"--TRAIN_NGPU={TRAIN_NGPU}\"\n",
    "    , f\"--reduction_cnt={REDUCTION_SERVER_COUNT}\"\n",
    "    , f\"--replica_count={REPLICA_COUNT}\"\n",
    "    , f\"--experiment_name={EXPERIMENT_NAME}\"\n",
    "    , f\"--experiment_run={RUN_NAME}\"\n",
    "]\n",
    "\n",
    "from utils import workerpool_specs\n",
    "\n",
    "WORKER_POOL_SPECS = workerpool_specs.prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=WORKER_ARGS,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    "    accelerator_type=TRAIN_GPU,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b034d8c-1fb4-4a68-8703-08c91e61727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/934903580331/locations/us-central1/tensorboards/1523017118516248576\n"
     ]
    }
   ],
   "source": [
    "vertex_ai_tb = vertex_ai.Tensorboard.create()\n",
    "TENSORBOARD = vertex_ai_tb.gca_resource.name\n",
    "print(TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49dca337-cd7d-48da-be3e-a2b82c9b1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    experiment=EXPERIMENT_NAME\n",
    "    # , experiment_tensorboard=vertex_ai_tb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13b0a5fe-7ef0-41c4-8075-f6c6b198c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_r4_job = vertex_ai.CustomJob(\n",
    "    display_name=f'imdb-bert-{RUN_NAME}-{DISTRIBUTION_STRATEGY}-{REPLICA_COUNT}-{TRAIN_NGPU}-r',\n",
    "    worker_pool_specs=WORKER_POOL_SPECS,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "905ff012-2336-4bfe-9a04-0c2ed5487dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_r4_job.run(\n",
    "    sync=False\n",
    "    , service_account=VERTEX_SA\n",
    "    , tensorboard=TENSORBOARD\n",
    "    , restart_job_on_worker_restart=False\n",
    "    , enable_web_access=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfd1ec01-6d46-4380-a56d-2bb8ca0b3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: imdb-bert-run-20230620-180730-multiworker-2-2-r\n",
      "Job Resource Name: projects/934903580331/locations/us-central1/customJobs/8357247007798067200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job Name: {custom_r4_job.display_name}\")\n",
    "print(f\"Job Resource Name: {custom_r4_job.resource_name}\\n\")\n",
    "# print(f\"Check training progress at {custom_m_job._dashboard_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a154e5d-db67-4bbe-9e74-f106ff11765c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
